<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.11"/>
<title>HCC: HCC Profile Mode</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { init_search(); });
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">HCC
   </div>
   <div id="projectbrief">HCC is a single-source, C/C++ compiler for heterogeneous computing.  It&#39;s optimized with HSA (http://www.hsafoundation.com/).</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.11 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li class="current"><a href="pages.html"><span>Related&#160;Pages</span></a></li>
      <li><a href="namespaces.html"><span>Namespaces</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">HCC Profile Mode </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>HCC supports low-overhead profiler to trace or summarize command timestamp information to stderr for any HCC or HIP program. Tho profiler messages are interleaved with the trace output from the application - which is handy to identify the region-of-interest and can complement deeper analysis with the CodeXL GUI Additionally, the hcc profiler requires only console mode access and can be used on machine where graphics are not available or are hard to access.</p>
<p>Some other useful features:</p><ul>
<li>Calculates the actual bandwidth for memory transfers</li>
<li>Identifies PeerToPeer memory copies</li>
<li>Shows queue, start, and stop timestamps for each command</li>
<li>Shows barrier commands and the time they spent waiting to resolve (if requested)</li>
</ul>
<p>HCC_PROFILE=2 enables a profile message after each command (kernel or data movement) completes. HCC_PROFILE=1 is a future capability that will shows a summary of kernel and data commands when hcc exits. (under development)</p>
<p>## One-liners </p><div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;# Trace collection:</div><div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;$ HCC_PROFILE=2  RunMyApp &amp;&gt; prof.out</div><div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;</div><div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;# Post-processing examples:</div><div class="line"><a name="l00005"></a><span class="lineno">    5</span>&#160;# Show summary</div><div class="line"><a name="l00006"></a><span class="lineno">    6</span>&#160;$ rpt prof.out</div><div class="line"><a name="l00007"></a><span class="lineno">    7</span>&#160;</div><div class="line"><a name="l00008"></a><span class="lineno">    8</span>&#160;# Show summary for a specified ROI for lines 100-200 of the file</div><div class="line"><a name="l00009"></a><span class="lineno">    9</span>&#160;$ rpt prof.out -r @100 --R @200</div><div class="line"><a name="l00010"></a><span class="lineno">   10</span>&#160;</div><div class="line"><a name="l00011"></a><span class="lineno">   11</span>&#160;# Generate text trace to stdout</div><div class="line"><a name="l00012"></a><span class="lineno">   12</span>&#160;$ rpt  prof.out -t</div><div class="line"><a name="l00013"></a><span class="lineno">   13</span>&#160;</div><div class="line"><a name="l00014"></a><span class="lineno">   14</span>&#160;# Generate gui trace for reading with chrome://tracing</div><div class="line"><a name="l00015"></a><span class="lineno">   15</span>&#160;$ rpt prof.out -g prof.json</div></div><!-- fragment --><h2>HCC text profile format</h2>
<h3>Kernel Commands</h3>
<p>This example shows profiled kernel commands: </p><div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;$ HCC_PROFILE=2 ./my-hcc-app ...</div><div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;profile:  kernel;            Im2Col;   17.8 us; 94859076277181; 94859076277181; 94859076294941; #0.3.1;</div><div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;profile:  kernel;  tg_betac_alphaab;   32.6 us; 94859076277181; 94859537593679; 94859537626319; #0.3.2;</div><div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;profile:  kernel;     MIOpenConvUni;  125.4 us; 94859076277181; 94860077852212; 94860077977651; #0.3.3;</div></div><!-- fragment --> <div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;PROFILE:  TYPE;    KERNEL_NAME     ;  DURATION;        ENQUEUE; START         ; STOP          ; ID</div></div><!-- fragment --><ul>
<li>PROFILE: always "profile:" to distinguish it from other output.</li>
<li>TYPE: the command type : kernel, copy, copyslo, or barrier. The examples and descriptions in this section are all kernel commands.</li>
<li>KERNEL_NAME: the (short) kernel name.</li>
<li>DURATION: command duration measured in us. This is measured using the GPU timestamps and represents the command execution on the acclerator device.</li>
<li>ENQUEUE: When the command is enqueued to the GPU from the host, measured in ns and using host-side timers. This timestamp is collected inside host API that enqueues the command.</li>
<li>START: When the command starts executing, measured in ns. For "fast" command executed by the GPU copy engines, this is measured using GPU-side timers.</li>
<li>STOP: When the command stops executing, measured in ns. For "fast" command executed by the GPU copy engines, this is measured using GPU-side timers.</li>
<li>ID: command id in device.queue.cmd format. The cmd number is a mononotically increasing per-queue, so the triple of device.queue.cmd uniquely identifies the command during the process execution.</li>
</ul>
<h3>Memory Copy Commands</h3>
<p>This example shows memory copy commands with full verbose output: </p><div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;profile: copyslo; HostToDevice_sync_slow;   909.2 us; 94858703002; 94858703102; 94858704012; #0.0.0; 2359296 bytes;  2.2 MB;   2.5 GB/s;</div><div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;profile:    copy; DeviceToHost_sync_fast;   117.0 us; 94858726008; 94858726408; 94858726525; #0.0.0; 1228800 bytes;  1.2 MB;   10.0 GB/s;</div><div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;profile:    copy; DeviceToHost_sync_fast;     9.0 us; 94858726068; 94858726668; 94858726677; #0.0.0; 400 bytes;      0.0 MB;   0.0 GB/s;</div><div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;profile:    copy; HostToDevice_sync_fast;    15.2 us; 94858727039; 94858727639; 94858727654; #0.0.0; 9600 bytes;     0.0 MB;   0.6 GB/s;</div><div class="line"><a name="l00005"></a><span class="lineno">    5</span>&#160;profile:    copy; HostToDevice_async_fast;  131.5 us; 94858729098; 94858729198; 94858729330; #0.6.1; 1228800 bytes;  1.2 MB;   8.9 GB/s;</div><div class="line"><a name="l00006"></a><span class="lineno">    6</span>&#160;PROFILE:  TYPE;    COPY_NAME             ;  DURATION;     ENQUEUE;       START;        STOP;  ID   ; SIZE_BYTES;     SIZE_MB;  BANDWIDTH;</div></div><!-- fragment --><ul>
<li>PROFILE: always "profile:" to distinguish it from other output.</li>
<li>TYPE: the command type : kernel, copy, copyslo,or barrier. The examples and descriptions in this section are all copy or copyslo commands.</li>
<li>COPY_NAME has 3 parts:<ul>
<li>Copy kind: HostToDevice, HostToHost, DeviceToHost, DeviceToDevice, or PeerToPeer. DeviceToDevice indicates the copy occurs on a single device while PeerToPeer indicates a copy between devices.</li>
<li>Sync or Async. Synchronous copies indicate the host waits for the completion for the copy. Asynchronous copies are launched by the host without waiting for the copy to complete.</li>
<li>Fast or Slow. Fast copies use the GPUs optimized copy routines from the hsa_amd_memory_copy routine. Slow copies typically involve unpinned host memory and can't take the fast path.</li>
<li>For example `HostToDevice_async_fast.</li>
</ul>
</li>
<li>DURATION: command duration measured in us. This is measured using the GPU timestamps and represents the command execution on the acclerator device.</li>
<li>ENQUEUE: When the command is enqueued to the GPU from the host, measured in ns and using host-side timers. This timestamp is collected inside host API that enqueues the command.</li>
<li>START: When the command starts executing, measured in ns. For "fast" command executed by the GPU copy engines, this is measured using GPU-side timers.</li>
<li>STOP: When the command stops executing, measured in ns. For "fast" command executed by the GPU copy engines, this is measured using GPU-side timers.</li>
<li>ID: command id in device.queue.cmd format. The cmdsequm is a unique mononotically increasing number per-queue, so the triple of device.queue.cmdseqnum uniquely identifies the command during the process execution.</li>
<li>SIZE_BYTES: the size of the transfer, measured in bytes.</li>
<li>SIZE_MB: the size of the transfer, measured in megabytes.</li>
<li>BANDWIDTH: the bandwidth of the transfer, measured in GB/s.</li>
</ul>
<h3>Barrier Commands</h3>
<p>An example barrier command with full vebosity: </p><div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;profile: barrier; deps:0_acq:none_rel:sys;  5.3 us; 94858731419410;  94858731419410; 94858731424690; #0.0.2;</div><div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;PROFILE:  TYPE;   BARRIER_NAME           ;  DURATION; ENQUEUE; START         ; STOP          ; ID    ; </div></div><!-- fragment --><ul>
<li>PROFILE: always "profile:" to distinguish it from other output.</li>
<li>TYPE: the command type: either kernel, copy, copyslo, or barrier. The examples and descriptions in this section are all copy commands. Copy indicates that the runtime used a call to the fast hsa memory copy routine while copyslo indicates that the copy was implemented with staging buffers or another less optimal path. copy computes the commands using device-side timestamps while copyslo computes the bandwidth based on host timestamps.</li>
<li>BARRIER_NAME has 3 parts:<ul>
<li>deps:# - the number of input dependencies into the barrier packet.</li>
<li>acq: - the acquire fence for the barrier. May be none, acc(accelerator or agent), sys(system). See HSA AQL spec for additional information.</li>
<li>rel: - the release fence for the barrier. May be none, acc(accelerator or agent), sys(system). See HSA AQL spec for additional information.</li>
</ul>
</li>
<li>DURATION: command duration measured in us. This is measured using the GPU timestamps from the time the barrier reaches the head of the queue to when it executes. Thus this includes the time to wait for all input dependencies, plus the previous command to complete, plus any fence operations performed by the barrier.</li>
<li>ENQUEUE: When the command is enqueued to the GPU from the host, measured in ns and using host-side timers. This timestamp is collected inside host API that enqueues the command.</li>
<li>START: When the command starts executing, measured in ns. For "fast" command executed by the GPU copy engines, this is measured using GPU-side timers.</li>
<li>STOP: When the command stops executing, measured in ns. For "fast" command executed by the GPU copy engines, this is measured using GPU-side timers.</li>
<li>ID: the command id in device.queue.cmd format. The cmdsequm is a unique mononotically increasing number per-queue, so the triple of device.queue.cmdseqnum uniquely identifies the command during the process execution.</li>
</ul>
<h3>Overhead</h3>
<p>The hcc profiler does not add any additional synchronization between commands or queues. Profile information is recorded when a command is "disposed" by the HCC runtime. This may differ from the order that commands are dispatched ; the rpt tool should be used to recover the original command order. The profile mode will allocate a signal for each command to record the timestamp information. This can add 1-2 us to the overall program execution for command which do not already use a completion signal. However, the command duration (start-stop) is still accurate. Trace mode will generate profile records to stderr which will likely impact the overall application exection time. However, the GPU duration and timestamps are still valid.</p>
<h3>Additional Details and tips</h3>
<ul>
<li>Commands are logged in the order they are removed from the internal HCC command tracker. Typically this is the same order that commands are dispatched, though sometimes these may diverge. For example, commands from different devices,queues, or cpu threads may be interleaved on the hcc trace display to stderr. If a single view in timeline order is required, enable and sort by the profiler START timestamps.</li>
<li>If the application keeps a reference to a completion_future, then the profile record may be reported significantly after it occurs. rpt can be used to print profile records in time-order.</li>
<li>Some timers are collected on the GPU and some on the CPU. These are normalized to the same clock domain and can compared.</li>
<li>Barriers include the time spent waiting for their dependents to complete. Barriers may begin executing before their dependents do, and can appear to have a very long execution time</li>
<li>HCC_PROFILE has an (untested) feature to write to a log file.</li>
<li>For profiling python commands with stderr and stdout, it can be useful to merge stdout into stderr so the RPT messages and markers are better interleaved with the text from the application.</li>
</ul>
<h2>rpt</h2>
<p>ROCm Profiling Tool ("rpt") is a command-line tool that post-processes the output from the HCC_PROFILE mode. Key features include:</p><ul>
<li>Sort profile records by time.</li>
<li>Compute gaps where GPUs or data busses are unused.</li>
<li>Display profile summaries for each resource (see below)</li>
<li>Display a textual trace of profile records.</li>
<li>Display a graphical trace of profile records. (can be viewed in chrome://tracing mode)</li>
<li>Powerful Region-of-Interest capabilities to select which regions contribute to the summary statistics. Useful for example to skip over initialization and warmup code.</li>
</ul>
<h4>Resources and Gaps</h4>
<p>rpt organizes profile records into the parent resources where they execute. Resources can currently be GPUs (numbered 0..N-1) or the DATA bus. GPU resources execute kernel and barrier commands. DATA resources execute copy commands.</p>
<p>Gaps indicate periods of times when the resource is not utilized. rpt computes gap time by examining the delta between the stop and start time of consecutive records on the resource. Commands may be overlapped or completely hidden if a command starts eariler - in this case the duration will be 0.</p>
<p>The summary view uses a histogram to aggregate gaps into buckets and will show the range covered by the bucket. For example, the "gap &gt;=10000us" buckets sumarizes all gaps which are equal or more than 10000us. Gaps are inclusive of the lower bound and exclusive of the upper bound. The &ndash;gaps option can be used to customize the histogram boundaries and this can be useful to isolate causes of gaps in some cases.</p>
<p>Large gaps can indicate the ROI is not set correctly - see the next section for suggestions on how to set the ROI. Inside a valid ROI:</p>
<ul>
<li>Gaps of &lt;10us typically indicate GPU hardware overhead - this is maximum rate that the GPU can execute back-to-back commands in the same queue. If this is significant overhead, it may be beneficial to combine kernels, or use multiple queues if the work is independent.</li>
<li>Larger gaps can indicate excessive host serialization or cases where the GPU was not fed commands frequently enough, perhaps due to some expensive CPU activity. To analyze the cause of these gaps, you can use a profiler such as operf or can use the --text_trace or --gui_trace options combined with progtram instrumentation (stderr output) to identify what is occurring in the gap regions.</li>
</ul>
<h4>Specifying ROI</h4>
<p>A common problem when performing profiling analysis is to determine which region to focus the analysis on, and in particular to exclude initialization, warmup, and tear-down activity from the results. RPT provides options to specify the start and stop of the "Region of Interest" (ROI) using line numbers from the input file, timestamps, or regular expressions. The latter is particularly useful - modify the program to emit a marker message and then search for the specified marker.</p>
<p>ROI_POINTs can be specified with line numbers, start times, or search strings.</p><ul>
<li>: specify a line number from the input file. Example: @1342.<br />
"\
- ^TIME    : specify start time from the beginning of the file.  Example: ^55.12345\n"\</li>
<li>MATCH_NUMSEARCH_RE : Specify string in python regular expression format, rpt will use the profile record after the found text. MATCH_NUM specifies the nth match in the file of the string. This allows applications to embed markers using simple stderr print statements and instruct rpt to include records only between the markers. Examples: MyStartMarker, 2MyStartMarker (finds 2nd instance of MyMarker), %"^iteration *10"</li>
</ul>
<h4>Text trace</h4>
<p>The <code>-t</code> option generates a text trace, with one row per profile record. Gaps between the records are also computed and displayed.</p>
<div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;Resource        Start(ms) +Time(us)    Type #Dev.Queue.Cmd    LineNum Name</div><div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;GPU0       980.530247:      +0.00 barrier #0.2.2586   195139: depcnt=0,acq=none,rel=sys</div><div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;DATA       166.264953: +814268.55 gap                ==============</div><div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;DATA       980.533506:      +2.67 copy    #0.2.2587   195140: HostToDevice_async_fast_128_bytes</div><div class="line"><a name="l00005"></a><span class="lineno">    5</span>&#160;GPU0       980.530247:     +11.70 gap                ====</div><div class="line"><a name="l00006"></a><span class="lineno">    6</span>&#160;GPU0       980.541950:      +0.00 barrier #0.2.2588   195138: depcnt=1,acq=none,rel=acc</div><div class="line"><a name="l00007"></a><span class="lineno">    7</span>&#160;GPU0       980.541950:    +223.59 gap                ==========</div><div class="line"><a name="l00008"></a><span class="lineno">    8</span>&#160;GPU0       980.765535:      +5.63 kernel  #0.1.192922   201310: TensorKernel</div><div class="line"><a name="l00009"></a><span class="lineno">    9</span>&#160;GPU0       980.771165:     +14.37 gap                ====</div><div class="line"><a name="l00010"></a><span class="lineno">   10</span>&#160;GPU0       980.785536:      +0.00 barrier #0.1.192923   201309: depcnt=0,acq=none,rel=acc</div><div class="line"><a name="l00011"></a><span class="lineno">   11</span>&#160;GPU0       980.785536:      +5.94 gap                ==</div><div class="line"><a name="l00012"></a><span class="lineno">   12</span>&#160;GPU0       980.791477:      +0.00 barrier #0.3.304   195141: depcnt=1,acq=none,rel=acc</div><div class="line"><a name="l00013"></a><span class="lineno">   13</span>&#160;GPU0       980.791477:      +7.70 gap                ==</div><div class="line"><a name="l00014"></a><span class="lineno">   14</span>&#160;GPU0       980.799181:      +0.00 barrier #0.3.305   195143: depcnt=0,acq=none,rel=sys</div><div class="line"><a name="l00015"></a><span class="lineno">   15</span>&#160;DATA       980.536173:    +272.19 gap                ==========</div><div class="line"><a name="l00016"></a><span class="lineno">   16</span>&#160;DATA       980.808366:      +2.37 copy    #0.3.306   195144: DeviceToHost_async_fast_4_bytes</div></div><!-- fragment --><ul>
<li>Resource : The resource this command executed on. May be GPU# for a specific GPU or DATA to indicate data transfer command</li>
<li>Time(us) : Time which the command contributed to the 'critical' path</li>
<li>Start(ms) : Start time of the command, displayed in ms. Command start from time 0</li>
<li>Type : Type of the command (kernel,barrier, copy)</li>
<li>Dev.Queue.Cmd : The cmd sequm is a unique mononotically increasing number per-queue, so the triple of device.queue.cmdseqnum uniquely identifies the command during the process execution.</li>
<li>LineNum : Line number from the input HCC_PROF_FILE</li>
<li>Name : Name of the record. For kernels, this is kernel name. For copy commands, the name contains the size and direction. For barrier commands this is contains dependency counts, acquire and release fences.</li>
</ul>
<p>Text output from the application(is shown interleaved with the profile records, preceded by leading "&gt;". The &ndash;hide_app_text option can be used to supress this if desired.</p>
<p>The gaps are shown with a series of '==" indicating their length - longer bars indicating a longer gap.. The &ndash;gaps parmater (or defaults if not specified) also controls the split points for the bar display. The intent is to provide a visually distinct way to visualize the length of the gaps.</p>
<p>The combined view interleaves the records for all resources, sorted by their start order. However, the time delta and gap computation are computed on a per-resource basis. For example, in the case above the large "DATA" gaps show the time since the last DATA command.</p>
<p>Copy commands show:</p><ul>
<li>Copy kind: HostToDevice, HostToHost, DeviceToHost, DeviceToDevice, or PeerToPeer. DeviceToDevice indicates the copy occurs on a single device while PeerToPeer indicates a copy between devices.</li>
<li>Sync or Async. Synchronous copies indicate the host waits for the completion for the copy. Asynchronous copies are launched by the host without waiting for the copy to complete.</li>
<li>Fast or Slow. Fast copies use the GPUs optimized copy routines from the hsa_amd_memory_copy routine. Slow copies typically involve unpinned host memory and can't take the fast path.</li>
<li>Size of the copy in bytes.</li>
</ul>
<p>Barrier commands show:</p><ul>
<li>depcnt=N : Number of other barriers this one depends on.</li>
<li>acq : The "acquire" fence executed before the barrier. May be "none", acc(meaning "accelerator" or "agent"), or "sys" ("system")</li>
<li>rel : The "release" fence executed before the barrier. May be "none", acc(meaning "accelerator" or "agent"), or "sys" ("system")</li>
<li>Dependent list (Under development) : List of dependents</li>
</ul>
<p>More information is available in the HSA Platofrm System Architecture Specification section 2.9 ("Architected Queueing Language").</p>
<p>The ROI controls apply to the text trace as well, and are useful to limit the generated text.</p>
<h4>GUI trace</h4>
<p>The <code>-g</code> or <code>--gui_trace</code> option generates a JSON-format file that can be input into chrome://tracing. Chrome tracing was originally designed for viewing browser performance information but is also a fully capable timeline viewing tool which is readily available on many platforms. To access the gui, start the Chrome brower and open the site "chrome://tracing". In the browser:</p><ul>
<li>Select "Load" from the upper left hand corner and navigate to the saved JSON file.</li>
<li>Select "?" from the upper right hand corner to see the navigation options.<ul>
<li>w/s Zoom in/out</li>
<li>a/d Pan left/right</li>
<li>Many more options available.</li>
</ul>
</li>
</ul>
<p>In the timeline view, each row shows a GPU queue or data resource. Rectangles indicate commands that execute on that row. More information can be obtained by clicking on the rectangle.</p>
<p>The ROI controls apply to the giu trace as well.</p>
<div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;# Use rpt to create a json gui trace file</div><div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;$ rpt prof.out -g prof.json</div></div><!-- fragment --><p> Start the Chrome brower and open the site "chrome://tracing". In the browswer, select "Load" from the upper left hand corner and navigate to the saved JSON file.</p>
<h3>Example profiling analysis</h3>
<div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;# Collect the profiling information for the application</div><div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;$ HCC_PROFILE=2 myapp &amp;&gt; myapp.prof</div></div><!-- fragment --><p>In this example, we had previously modified the program to print the message "iteration start" before every 10 iterations in the critical loop. We use the markers to filter the information parsed by roi, so we are examining exactly one iteration (specifically the profile records printed between the 3rd and 4th ocurrences of the phrase "iteration start" at the beginning of a line). By default, rpt emits a summary table showing the top users of each resource:</p>
<div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;$ rpt -r 3%&quot;^iteration start&quot; -R 4%&quot;^iteration start&quot;</div><div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;</div><div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;ROI_START: GPU0         0.000000:      +0.00  kernel   195169: miog_alphaab                   #0.1.199064</div><div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;ROI_STOP : GPU0      6819.188139:      +0.00  kernel   288991: miog_betac_alphaab             #0.1.282703</div><div class="line"><a name="l00005"></a><span class="lineno">    5</span>&#160;ROI_TIME=   6.819 secs</div><div class="line"><a name="l00006"></a><span class="lineno">    6</span>&#160;Resource=GPU0 Showing 20/84 records   78.43% busy</div><div class="line"><a name="l00007"></a><span class="lineno">    7</span>&#160;      Total(%)    Time(ms)    Calls  Avg(us)  Min(us)  Max(us)  Name</div><div class="line"><a name="l00008"></a><span class="lineno">    8</span>&#160;        17.69%  1206185.8    23064     52.3     20.1    676.2  miog_betac_alphaab</div><div class="line"><a name="l00009"></a><span class="lineno">    9</span>&#160;        11.34%   773334.6       10  77333.5  75585.2  84103.3  gap&gt;=10000us</div><div class="line"><a name="l00010"></a><span class="lineno">   10</span>&#160;         9.17%   625546.4      769    813.5    204.0   1810.3  MIOpenConv1x1</div><div class="line"><a name="l00011"></a><span class="lineno">   11</span>&#160;         7.98%   544091.0      420   1295.5    417.9   3776.7  sp3AsmConvRxSF</div><div class="line"><a name="l00012"></a><span class="lineno">   12</span>&#160;         6.77%   461441.2    81499      5.7      0.1      9.6  gap&lt;10us</div><div class="line"><a name="l00013"></a><span class="lineno">   13</span>&#160;         5.60%   382048.1     7718     49.5     28.7    145.2  miog_alphaab</div><div class="line"><a name="l00014"></a><span class="lineno">   14</span>&#160;         4.55%   310281.5    11200     27.7     12.0     95.6  Col2Im</div><div class="line"><a name="l00015"></a><span class="lineno">   15</span>&#160;         3.39%   231113.1       50   4622.3   2562.4  12843.2  MIOpenConvUni</div><div class="line"><a name="l00016"></a><span class="lineno">   16</span>&#160;         3.37%   229728.0    12478     18.4      7.0     65.9  Im2Col</div><div class="line"><a name="l00017"></a><span class="lineno">   17</span>&#160;         2.80%   190663.2      273    698.4    121.0   3323.0  mloPooling</div><div class="line"><a name="l00018"></a><span class="lineno">   18</span>&#160;         2.25%   153615.5       99   1551.7    700.8   7101.0  gcnAsmConv3x3WrW</div><div class="line"><a name="l00019"></a><span class="lineno">   19</span>&#160;         1.99%   135681.8      199    681.8    416.3   2355.9  sp3AsmConv3x3F</div><div class="line"><a name="l00020"></a><span class="lineno">   20</span>&#160;         1.80%   122478.6       85   1440.9    191.4   2055.6  mloPoolingAveBwd</div><div class="line"><a name="l00021"></a><span class="lineno">   21</span>&#160;         1.55%   105427.5       90   1171.4    693.3   1438.2  MLOpenCvBwdWrWLmap</div><div class="line"><a name="l00022"></a><span class="lineno">   22</span>&#160;         1.48%   106004.4      940    112.8     17.5   1590.7  TensorAdder::ScalarSumSquares&lt;float&gt;</div><div class="line"><a name="l00023"></a><span class="lineno">   23</span>&#160;         1.38%    94248.5      331    284.7    101.0    997.7  gap&lt;1000us</div><div class="line"><a name="l00024"></a><span class="lineno">   24</span>&#160;         1.37%    93703.6       40   2342.6   1347.6   5417.6  MIOpenCvBwdWrW</div><div class="line"><a name="l00025"></a><span class="lineno">   25</span>&#160;         1.29%    87982.8       26   3384.0   1035.7   7178.7  gap&lt;10000us</div><div class="line"><a name="l00026"></a><span class="lineno">   26</span>&#160;         1.20%    82023.0      280    292.9     53.2   1909.4  BatchNormBwdSpatialDX</div><div class="line"><a name="l00027"></a><span class="lineno">   27</span>&#160;         1.05%    71775.9     2340     30.7      3.9    131.7  TensorOp</div><div class="line"><a name="l00028"></a><span class="lineno">   28</span>&#160;</div><div class="line"><a name="l00029"></a><span class="lineno">   29</span>&#160;Resource=DATA Showing 8/8 records    0.00% busy</div><div class="line"><a name="l00030"></a><span class="lineno">   30</span>&#160;      Total(%)    Time(ms)    Calls  Avg(us)  Min(us)  Max(us)  Name</div><div class="line"><a name="l00031"></a><span class="lineno">   31</span>&#160;        93.20%  6355648.1        9 706183.1 693182.3 716972.0  gap&gt;=10000us</div><div class="line"><a name="l00032"></a><span class="lineno">   32</span>&#160;         0.12%     8100.3       21    385.7    161.7    636.0  gap&lt;1000us</div><div class="line"><a name="l00033"></a><span class="lineno">   33</span>&#160;         0.01%      666.9        8     83.4     76.4     94.5  gap&lt;100us</div><div class="line"><a name="l00034"></a><span class="lineno">   34</span>&#160;         0.00%       70.1        2     35.0     24.7     45.3  gap&lt;50us</div><div class="line"><a name="l00035"></a><span class="lineno">   35</span>&#160;         0.00%       67.7       30      2.3      1.9      2.7  DeviceToHost_async_fast_4_bytes</div><div class="line"><a name="l00036"></a><span class="lineno">   36</span>&#160;         0.00%       41.4        9      4.6      2.7      6.3  gap&lt;10us</div><div class="line"><a name="l00037"></a><span class="lineno">   37</span>&#160;         0.00%       28.6       10      2.9      2.7      3.1  HostToDevice_async_fast_4_bytes</div><div class="line"><a name="l00038"></a><span class="lineno">   38</span>&#160;         0.00%       27.7       10      2.8      2.7      3.1  HostToDevice_async_fast_128_bytes</div></div><!-- fragment --><h4>Observations and further analysis</h4>
<ul>
<li>This GPU is used only ~78% of the time. The remaining 22% of time is displayed in the "gap" categories ; about half this comes from the second row showing 10 gaps averaging 77ms. These are relatively large gaps and likely indicate the CPU is not feeding the GPU quickly enough. One approach would be to use the <code>-t</code> option and examine the kernels and other profile activity around the gap. Another approach is to use oprofile (see the next section).</li>
<li>The miog_betac_alphaab and MIOpenConv1x kernels take 17.69% and 9.17% of the overall GPU execution time respectively. Optimizing thise or choosing alternate algorithms could improve performance significantly.</li>
<li>The DATA resource is used very infrequently, nearly 0% active with only 8 records and plenty of gaps.</li>
</ul>
<h2>oprofile</h2>
<h3>Introduction</h3>
<ul>
<li><a href="http://oprofile.sourceforge.net/docs/">http://oprofile.sourceforge.net/docs/</a></li>
<li><a href="https://www.ibm.com/support/knowledgecenter/linuxonibm/liacf/oprofile_pdf.pdf">https://www.ibm.com/support/knowledgecenter/linuxonibm/liacf/oprofile_pdf.pdf</a></li>
</ul>
<h3>Installation</h3>
<p>$ apt-get install oprofile</p>
<h3>Data Collection</h3>
<p>Start the program of interest. </p><div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;$ ./myapp</div></div><!-- fragment --><p>In another terminal, determine the process id (perhaps with <code>pgrep</code>) and pass to ``<code> $ operf --pid</code>pgrep myapp` </p><div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;By default, operf will backup any previously recorded perf data and create a new file.</div><div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;</div><div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;### Data Reporting</div></div><!-- fragment --> <h1>Show callgraph</h1>
<p>$ opreport -cl</p>
<h1>Show hotspots in code:</h1>
<p>$ opreport -dg ``` </p>
</div></div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated on Wed Dec 13 2017 13:11:17 for HCC by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.11
</small></address>
</body>
</html>
